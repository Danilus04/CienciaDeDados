{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os \n",
    "from pathlib import Path\n",
    "import pandas as pd, pyarrow as pa\n",
    "import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957d6e4",
   "metadata": {},
   "source": [
    "# Tarefa 1: Setup e Consolidação dos Dados\n",
    "1. Download automatizado:\n",
    "\n",
    "    * Códigos para baixar arquivos mensais de 2023 e 2024 (meta: 24 meses, mínimo: 12\n",
    "        meses)\n",
    "\n",
    "    * Encontrar os dados e o padrão da URL em:\n",
    "        `https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page`\n",
    "\n",
    "    * Focar apenas nos Yellow Taxi Trip Records\n",
    "\n",
    "    * Verificar integridade dos arquivos e tratar erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee493354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padrão:\n",
    "# ano em yyyy\n",
    "# mes em mm\n",
    "# `https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{ano}-{mes}.parquet`\n",
    "\n",
    "def baixar_arquivo_com_pathlib(url, pasta_destino):\n",
    "    pasta = Path(pasta_destino)\n",
    "    # Garante que a pasta de destino exista\n",
    "    pasta.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    nome_arquivo = url.split('/')[-1]\n",
    "    caminho_local = pasta / nome_arquivo \n",
    "\n",
    "    print(f\"Baixando '{nome_arquivo}' de '{url}'...\")\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(caminho_local, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"Download concluído com sucesso! Arquivo salvo em: {caminho_local}\")\n",
    "        return caminho_local\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro ao baixar o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "url_do_arquivo = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "pasta_para_salvar = \"data\"\n",
    "\n",
    "meses = [f\"{i:02d}\" for i in range(1, 13)]\n",
    "anos = ['2023','2024']\n",
    "\n",
    "# PODE QUEBRAR COM OS DADOS DE 2025 QUE NÃO TEM OS DADOS DE TODOS OS MESES MESES \n",
    "for ano in anos:\n",
    "    for mes in meses:\n",
    "        \n",
    "        baixar_arquivo_com_pathlib(\n",
    "            f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{ano}-{mes}.parquet\", \n",
    "            pasta_para_salvar\n",
    "        )\n",
    "\n",
    "# VERIFICAR A INTEGRIDADE DOS ARQUIVOS \n",
    "\n",
    "#print(f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{ano}-{mes}.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6797748",
   "metadata": {},
   "source": [
    "## 2. Análise de schema:\n",
    "* Examine estrutura dos arquivos Parquet\n",
    "* Identifique e cuide de mudanças de schema entre diferentes meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando os arquivos\n",
    "\n",
    "# Ler arquivo parquet\n",
    "\n",
    "meses = [f\"{i:02d}\" for i in range(1, 13)]\n",
    "anos = ['2023','2024']\n",
    "\n",
    "base_path = \"data\"  # pasta onde estão os arquivos\n",
    "schemas = {}\n",
    "\n",
    "for ano in anos:\n",
    "    for mes in meses:\n",
    "        file_name = f\"yellow_tripdata_{ano}-{mes}.parquet\"\n",
    "        file_path = os.path.join(base_path, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Lê apenas o schema sem carregar tudo na memória\n",
    "                df = pd.read_parquet(file_path, engine=\"fastparquet\")\n",
    "\n",
    "                # Guarda colunas e tipos em dicionário\n",
    "                schemas[file_name] = {col: str(dtype) for col, dtype in df.dtypes.items()}\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao ler {file_name}: {e}\")\n",
    "\n",
    "# Agora vamos comparar os schemas\n",
    "all_columns = set()\n",
    "for schema in schemas.values():\n",
    "    all_columns.update(schema.keys())\n",
    "\n",
    "print(\"\\n=== Diferenças detectadas ===\\n\")\n",
    "for file, schema in schemas.items():\n",
    "    missing = all_columns - set(schema.keys())\n",
    "    extra = set(schema.keys()) - all_columns\n",
    "    if missing or extra:\n",
    "        print(f\"{file}:\")\n",
    "        if missing:\n",
    "            print(f\"  - Faltando colunas: {missing}\")\n",
    "        if extra:\n",
    "            print(f\"  - Colunas extras: {extra}\")\n",
    "\n",
    "# Comparar tipos coluna a coluna\n",
    "print(\"\\n=== Divergências de tipos ===\\n\")\n",
    "for col in all_columns:\n",
    "    tipos = {}\n",
    "    for file, schema in schemas.items():\n",
    "        if col in schema:\n",
    "            tipos[file] = schema[col]\n",
    "    if len(set(tipos.values())) > 1:\n",
    "        print(f\"Coluna '{col}' com tipos diferentes:\")\n",
    "        for file, tipo in tipos.items():\n",
    "            print(f\"  {file}: {tipo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correção destes problemas\n",
    "\n",
    "files = glob.glob(\"data/yellow_tripdata_*.parquet\")\n",
    "\n",
    "# Colunas padrão (ajustadas para minúsculas)\n",
    "colunas_padrao = [\n",
    "    \"vendorid\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "    \"passenger_count\", \"trip_distance\", \"ratecodeid\", \"store_and_fwd_flag\",\n",
    "    \"pulocationid\", \"dolocationid\", \"payment_type\", \"fare_amount\",\n",
    "    \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\",\n",
    "    \"total_amount\", \"congestion_surcharge\", \"airport_fee\"\n",
    "]\n",
    "\n",
    "# Tipos alvo\n",
    "dtype_fix = {\n",
    "    \"vendorid\": \"Int32\",\n",
    "    \"pulocationid\": \"Int32\",\n",
    "    \"dolocationid\": \"Int32\",\n",
    "    \"payment_type\": \"Int32\",\n",
    "    \"passenger_count\": \"Int32\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"tpep_pickup_datetime\": \"datetime64[ns]\",\n",
    "    \"tpep_dropoff_datetime\": \"datetime64[ns]\",\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_parquet(f, engine=\"pyarrow\")\n",
    "    \n",
    "    # padronizar nomes\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # garantir colunas padrão (faltantes = NaN)\n",
    "    df = df.reindex(columns=colunas_padrao)\n",
    "    \n",
    "    # aplicar dtypes\n",
    "    for col, tipo in dtype_fix.items():\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                df[col] = df[col].astype(tipo)\n",
    "            except Exception:\n",
    "                # fallback: se não converter, deixa como está\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\") if \"float\" in tipo or \"int\" in tipo else df[col]\n",
    "    \n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenar\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Salvar unificado\n",
    "df_final.to_parquet(\"yellow_tripdata_all.parquet\", engine=\"pyarrow\", compression=\"snappy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b83b1d",
   "metadata": {},
   "source": [
    "## 3. Limpeza de dados\n",
    "* Remover registros com duração de viagem negativa ou zero\n",
    "* Filtrar coordenadas inválidas (fora dos ranges de latitude/longitude)\n",
    "* Eliminar valores negativos em campos monetários\n",
    "* Remover registros com passenger_count = 0\n",
    "* Validar datas dentro do período esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca6034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

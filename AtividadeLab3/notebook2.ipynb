{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91772b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd, pyarrow as pa\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict, Any, List\n",
    "import csv\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f49724",
   "metadata": {},
   "source": [
    "## 3. Benchmark de consultas :\n",
    "* Receita por zona: TOP 10 zonas de pickup por receita total média\n",
    "* Padrões temporais: Agregação por mês/semana (COUNT viagens, SUM receita, AVG distância)\n",
    "* Horário de pico: Ranking de horários mais movimentados usando window functions (RANK/ROW_NUMBER)\n",
    "* Análise de gorjeta: Taxa de gorjeta média por borough usando CASE WHEN para categorizar\n",
    "* Viagens longas vs curtas: Comparativo usando CASE para categorizar distâncias\n",
    "\n",
    "## 4. Para cada consulta escolhida, você deve:\n",
    "* Implementar em SQL (DuckDB) e validar os resultados inspecionando os dados\n",
    "* Implementar equivalente em Pandas e verificar se os resultados são consistentes\n",
    "* Anotar quais consultas falharam no Pandas (memória, tempo, erro)\n",
    "* Medir tempo de execução rodando cada consulta 5 vezes em cada ferramenta\n",
    "* Registrar apenas consultas que executaram com sucesso para comparação de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d727344",
   "metadata": {},
   "source": [
    "### 4.1 Receita por zona: TOP 10 zonas de pickup por receita total média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43828596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Executando consulta em DuckDB (SQL) ===\n",
      "DuckDB successful runs: 5 / 5, times: [0.11354209994897246, 0.08971410000231117, 0.08790849999058992, 0.09429989999625832, 0.0890289000235498]\n",
      "\n",
      "=== Executando consulta em Pandas ===\n",
      "Pandas successful runs: 5 / 5, times: [1.426865000044927, 1.315702199935913, 1.2890115000773221, 1.2761596000054851, 1.2240158000495285]\n",
      "\n",
      "=== Comparação DuckDB x Pandas ===\n",
      "Pulocationid order identical: True\n",
      "Max abs difference in avg_total_amount: 1.5802470443304628e-11\n",
      "\n",
      "Relatório salvo em: analysis_results\\benchmark_report.csv\n",
      "DuckDB top10 salvo em: analysis_results\\duckdb_top10_by_avg.csv\n",
      "Pandas top10 salvo em: analysis_results\\pandas_top10_by_avg.csv\n",
      "\n",
      "=== Sumário de performance (apenas runs bem-sucedidas) ===\n",
      "DuckDB: runs=5, mean=0.095s, median=0.090s, min=0.088s, max=0.114s\n",
      "Pandas: runs=5, mean=1.306s, median=1.289s, min=1.224s, max=1.427s\n"
     ]
    }
   ],
   "source": [
    "PARQUET_PATH = \"data/cleaned/yellow_tripdata_clean_snappy.parquet\"  # ajuste se necessário\n",
    "OUTPUT_DIR = \"analysis_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SQL_QUERY = \"\"\"\n",
    "-- Top 10 pickup zones by average revenue (total_amount)\n",
    "SELECT\n",
    "  pulocationid,\n",
    "  AVG(total_amount) AS avg_total_amount,\n",
    "  COUNT(*) AS trips\n",
    "FROM parquet_scan('{parquet}')\n",
    "GROUP BY pulocationid\n",
    "ORDER BY avg_total_amount DESC\n",
    "LIMIT 10;\n",
    "\"\"\".format(parquet=PARQUET_PATH)\n",
    "\n",
    "# If you want TOTAL revenue instead of average, use:\n",
    "# SQL_QUERY_SUM = \"\"\"\n",
    "# SELECT pulocationid, SUM(total_amount) AS total_amount, COUNT(*) AS trips\n",
    "# FROM parquet_scan('{parquet}')\n",
    "# GROUP BY pulocationid\n",
    "# ORDER BY total_amount DESC\n",
    "# LIMIT 10;\n",
    "# \"\"\".format(parquet=PARQUET_PATH)\n",
    "\n",
    "REPEATS = 5\n",
    "TIMEOUT_SECONDS = None  # ajuste se quiser impor timeout logic\n",
    "\n",
    "def time_function(func, *args, repeats=5) -> Tuple[List[float], Any, Exception]:\n",
    "    \"\"\"\n",
    "    Run func(*args) repeats times. Return list of successful times, last result (if any), and last exception (if failed).\n",
    "    We stop collecting a failing run but continue trying subsequent repeats.\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    last_result = None\n",
    "    last_exc = None\n",
    "    for i in range(repeats):\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            res = func(*args)\n",
    "            elapsed = time.perf_counter() - start\n",
    "            times.append(elapsed)\n",
    "            last_result = res\n",
    "            last_exc = None\n",
    "        except Exception as e:\n",
    "            elapsed = time.perf_counter() - start\n",
    "            last_exc = e\n",
    "            # record failure but continue\n",
    "            print(f\"Run {i+1} failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "    return times, last_result, last_exc\n",
    "\n",
    "##### 1) RUN WITH DUCKDB (SQL) #####\n",
    "def duckdb_query_run(sql: str):\n",
    "    # returns pandas.DataFrame result\n",
    "    # Create a fresh in-memory connection each run to avoid caching side-effects\n",
    "    conn = duckdb.connect(database=\":memory:\")\n",
    "    try:\n",
    "        # Use parquet_scan to let DuckDB stream parquet without fully materializing on Python side\n",
    "        df = conn.execute(sql).df()\n",
    "    finally:\n",
    "        conn.close()\n",
    "    return df\n",
    "\n",
    "print(\"=== Executando consulta em DuckDB (SQL) ===\")\n",
    "duckdb_times, duckdb_result, duckdb_exc = time_function(duckdb_query_run, SQL_QUERY, repeats=REPEATS)\n",
    "duckdb_successful = len(duckdb_times) > 0\n",
    "print(f\"DuckDB successful runs: {len(duckdb_times)} / {REPEATS}, times: {duckdb_times}\")\n",
    "if duckdb_successful:\n",
    "    duckdb_result.to_csv(os.path.join(OUTPUT_DIR, \"duckdb_top10_by_avg.csv\"), index=False)\n",
    "\n",
    "##### 2) RUN WITH PANDAS #####\n",
    "# We implement Pandas equivalent: read needed columns from parquet and compute groupby.\n",
    "# To reduce memory, we read only columns we need.\n",
    "PANDAS_COLUMNS = [\"pulocationid\", \"total_amount\"]  # keep minimal set\n",
    "\n",
    "def pandas_query_run(parquet_path: str):\n",
    "    # This will attempt to load the necessary columns into memory and run the groupby\n",
    "    # For large datasets this may raise MemoryError\n",
    "    # We attempt to cast pulocationid to Int32 to keep memory smaller if possible\n",
    "    df = pd.read_parquet(parquet_path, columns=PANDAS_COLUMNS, engine=\"pyarrow\")\n",
    "    # Drop missing pulocationid or total_amount\n",
    "    df = df.dropna(subset=[\"pulocationid\", \"total_amount\"])\n",
    "    # Ensure types\n",
    "    # If pulocationid is float due to earlier NaNs, convert to integer (nullable)\n",
    "    if not pd.api.types.is_integer_dtype(df[\"pulocationid\"].dtype):\n",
    "        df[\"pulocationid\"] = df[\"pulocationid\"].astype(\"Int32\")\n",
    "    # Groupby average\n",
    "    result = (\n",
    "        df.groupby(\"pulocationid\", observed=True, dropna=True)\n",
    "          .agg(avg_total_amount=(\"total_amount\", \"mean\"), trips=(\"total_amount\",\"size\"))\n",
    "          .reset_index()\n",
    "          .sort_values(\"avg_total_amount\", ascending=False)\n",
    "          .head(10)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "print(\"\\n=== Executando consulta em Pandas ===\")\n",
    "pandas_times, pandas_result, pandas_exc = time_function(pandas_query_run, PARQUET_PATH, repeats=REPEATS)\n",
    "pandas_successful = len(pandas_times) > 0\n",
    "print(f\"Pandas successful runs: {len(pandas_times)} / {REPEATS}, times: {pandas_times}\")\n",
    "if pandas_successful and pandas_result is not None:\n",
    "    pandas_result.to_csv(os.path.join(OUTPUT_DIR, \"pandas_top10_by_avg.csv\"), index=False)\n",
    "\n",
    "##### 3) VALIDAR CONSISTÊNCIA ENTRE RESULTADOS (se ambos sucederam) #####\n",
    "def compare_topk(df1: pd.DataFrame, df2: pd.DataFrame, k=10, atol=1e-6) -> Dict[str, Any]:\n",
    "    \"\"\"Compare two top-k results by pulocationid and avg_total_amount within tolerance.\"\"\"\n",
    "    out = {\"match_pulocationid\": False, \"max_abs_diff\": None, \"differences\": None}\n",
    "    if df1 is None or df2 is None:\n",
    "        out[\"differences\"] = \"one of results is None\"\n",
    "        return out\n",
    "    # Normalize ordering by pulocationid\n",
    "    d1 = df1.set_index(\"pulocationid\").sort_index()\n",
    "    d2 = df2.set_index(\"pulocationid\").sort_index()\n",
    "    common = d1.index.intersection(d2.index)\n",
    "    out[\"match_pulocationid\"] = list(d1.index) == list(d2.index)\n",
    "    # compute absolute differences for matching pulocationids\n",
    "    diffs = {}\n",
    "    max_abs = 0.0\n",
    "    for pid in common:\n",
    "        a = float(d1.at[pid, \"avg_total_amount\"])\n",
    "        b = float(d2.at[pid, \"avg_total_amount\"])\n",
    "        diff = abs(a - b)\n",
    "        diffs[pid] = diff\n",
    "        if diff > max_abs:\n",
    "            max_abs = diff\n",
    "    out[\"max_abs_diff\"] = max_abs\n",
    "    out[\"differences\"] = diffs\n",
    "    return out\n",
    "\n",
    "comparison = None\n",
    "if duckdb_successful and pandas_successful:\n",
    "    comparison = compare_topk(duckdb_result, pandas_result)\n",
    "    print(\"\\n=== Comparação DuckDB x Pandas ===\")\n",
    "    print(\"Pulocationid order identical:\", comparison[\"match_pulocationid\"])\n",
    "    print(\"Max abs difference in avg_total_amount:\", comparison[\"max_abs_diff\"])\n",
    "    if comparison[\"max_abs_diff\"] and comparison[\"max_abs_diff\"] > 1e-6:\n",
    "        print(\"Diferenças por pulocationid:\", comparison[\"differences\"])\n",
    "\n",
    "##### 4) Montar relatório de timings e salvar #####\n",
    "report_path = os.path.join(OUTPUT_DIR, \"benchmark_report.csv\")\n",
    "with open(report_path, \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"tool\", \"run_index\", \"time_seconds\", \"success\", \"error\"])\n",
    "    # DuckDB runs\n",
    "    for i in range(REPEATS):\n",
    "        success = i < len(duckdb_times)\n",
    "        t = duckdb_times[i] if i < len(duckdb_times) else None\n",
    "        err = \"\" if success else (str(duckdb_exc) if duckdb_exc else \"failed\")\n",
    "        writer.writerow([\"duckdb\", i+1, t, success, err])\n",
    "    # Pandas runs\n",
    "    for i in range(REPEATS):\n",
    "        success = i < len(pandas_times)\n",
    "        t = pandas_times[i] if i < len(pandas_times) else None\n",
    "        err = \"\" if success else (str(pandas_exc) if pandas_exc else \"failed\")\n",
    "        writer.writerow([\"pandas\", i+1, t, success, err])\n",
    "\n",
    "print(f\"\\nRelatório salvo em: {report_path}\")\n",
    "if duckdb_successful:\n",
    "    print(\"DuckDB top10 salvo em:\", os.path.join(OUTPUT_DIR, \"duckdb_top10_by_avg.csv\"))\n",
    "if pandas_successful:\n",
    "    print(\"Pandas top10 salvo em:\", os.path.join(OUTPUT_DIR, \"pandas_top10_by_avg.csv\"))\n",
    "\n",
    "##### 5) Sumário final (apenas execuções bem-sucedidas)\n",
    "def summarize_times(name: str, times: List[float]):\n",
    "    if not times:\n",
    "        return f\"{name}: 0 successful runs\"\n",
    "    import statistics\n",
    "    return (f\"{name}: runs={len(times)}, mean={statistics.mean(times):.3f}s, \"\n",
    "            f\"median={statistics.median(times):.3f}s, min={min(times):.3f}s, max={max(times):.3f}s\")\n",
    "\n",
    "print(\"\\n=== Sumário de performance (apenas runs bem-sucedidas) ===\")\n",
    "print(summarize_times(\"DuckDB\", duckdb_times))\n",
    "print(summarize_times(\"Pandas\", pandas_times))\n",
    "\n",
    "# Nota sobre falhas\n",
    "failures = []\n",
    "if not duckdb_successful:\n",
    "    failures.append(\"DuckDB failed\")\n",
    "if not pandas_successful:\n",
    "    failures.append(\"Pandas failed\")\n",
    "if failures:\n",
    "    print(\"\\nObservações: Algumas ferramentas falharam. Anotei nas colunas do CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e7940a",
   "metadata": {},
   "source": [
    "### 4.2 Padrões temporais: Agregação por mês/semana (COUNT viagens, SUM receita, AVG distância)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd93a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DuckDB ===\n",
      "       month       week  total_viagens  receita_total  distancia_media\n",
      "0 2023-01-01 2023-01-30         175517   4.824456e+06         3.333357\n",
      "1 2023-01-01 2023-01-16         678519   1.854441e+07         3.391944\n",
      "2 2023-01-01 2023-01-02         610212   1.715389e+07         3.669232\n",
      "3 2023-01-01 2022-12-26          71176   2.208902e+06         5.188594\n",
      "4 2023-01-01 2023-01-09         688707   1.881083e+07         3.399218\n",
      "Tempo médio DuckDB: 0.322s\n",
      "\n",
      "=== Pandas ===\n",
      "       month       week  total_viagens  receita_total  distancia_media\n",
      "0 2023-01-01 2022-12-26          71176     2208901.82         5.188594\n",
      "1 2023-01-01 2023-01-02         610212    17153888.42         3.669232\n",
      "2 2023-01-01 2023-01-09         688707    18810826.76         3.399218\n",
      "3 2023-01-01 2023-01-16         678519    18544410.30         3.391944\n",
      "4 2023-01-01 2023-01-23         693696    18573693.40         3.236062\n",
      "Tempo médio Pandas: 16.270s\n",
      "\n",
      "=== Validação ===\n",
      "Diferença total_viagens: 0\n",
      "Diferença receita_total: 4.315376281738281e-05\n",
      "\n",
      "=== Comparação Final ===\n",
      "                         Consulta Ferramenta  Tempo Médio (s)  Sucesso  \\\n",
      "0  Padrões temporais (mês/semana)     DuckDB            0.322     True   \n",
      "1  Padrões temporais (mês/semana)     Pandas           16.270     True   \n",
      "\n",
      "                 Observações  \n",
      "0  Execução rápida e estável  \n",
      "1                         OK  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_parquet(PARQUET_PATH, engine=\"pyarrow\")\n",
    "\n",
    "# ============================================================\n",
    "# 1️⃣ Verificar colunas necessárias\n",
    "# ============================================================\n",
    "\n",
    "required_cols = ['tpep_pickup_datetime', 'trip_distance', 'total_amount']\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Colunas faltando no dataframe: {missing}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2️⃣ Consulta em DuckDB\n",
    "# ============================================================\n",
    "duckdb.register(\"trips\", df)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    DATE_TRUNC('month', tpep_pickup_datetime) AS month,\n",
    "    DATE_TRUNC('week', tpep_pickup_datetime) AS week,\n",
    "    COUNT(*) AS total_viagens,\n",
    "    SUM(total_amount) AS receita_total,\n",
    "    AVG(trip_distance) AS distancia_media\n",
    "FROM trips\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "\n",
    "tempos_duckdb = []\n",
    "resultado_duckdb = None\n",
    "\n",
    "for i in range(5):\n",
    "    t0 = time.time()\n",
    "    resultado_duckdb = duckdb.sql(sql_query).df()\n",
    "    t1 = time.time()\n",
    "    tempos_duckdb.append(t1 - t0)\n",
    "\n",
    "tempo_medio_duckdb = sum(tempos_duckdb) / len(tempos_duckdb)\n",
    "\n",
    "print(f\"\\n=== DuckDB ===\")\n",
    "print(resultado_duckdb.head())\n",
    "print(f\"Tempo médio DuckDB: {tempo_medio_duckdb:.3f}s\")\n",
    "\n",
    "# ============================================================\n",
    "# 3️⃣ Consulta equivalente em Pandas\n",
    "# ============================================================\n",
    "tempos_pandas = []\n",
    "resultado_pandas = None\n",
    "pandas_ok = True\n",
    "erro_pandas = None\n",
    "\n",
    "try:\n",
    "    for i in range(5):\n",
    "        t0 = time.time()\n",
    "        resultado_pandas = (\n",
    "            df\n",
    "            .assign(\n",
    "                month=df[\"tpep_pickup_datetime\"].dt.to_period(\"M\").dt.to_timestamp(),\n",
    "                week=df[\"tpep_pickup_datetime\"].dt.to_period(\"W\").dt.start_time\n",
    "            )\n",
    "            .groupby([\"month\", \"week\"], as_index=False)\n",
    "            .agg(\n",
    "                total_viagens=(\"tpep_pickup_datetime\", \"count\"),\n",
    "                receita_total=(\"total_amount\", \"sum\"),\n",
    "                distancia_media=(\"trip_distance\", \"mean\")\n",
    "            )\n",
    "            .sort_values(\"month\")\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        tempos_pandas.append(t1 - t0)\n",
    "\n",
    "    tempo_medio_pandas = sum(tempos_pandas) / len(tempos_pandas)\n",
    "\n",
    "    print(f\"\\n=== Pandas ===\")\n",
    "    print(resultado_pandas.head())\n",
    "    print(f\"Tempo médio Pandas: {tempo_medio_pandas:.3f}s\")\n",
    "\n",
    "except Exception as e:\n",
    "    pandas_ok = False\n",
    "    erro_pandas = str(e)\n",
    "    print(\"\\n❌ Erro ao executar com Pandas:\", erro_pandas)\n",
    "\n",
    "# ============================================================\n",
    "# 4️⃣ Validação de consistência\n",
    "# ============================================================\n",
    "if pandas_ok:\n",
    "    try:\n",
    "        diff_viagens = abs(resultado_duckdb[\"total_viagens\"].sum() - resultado_pandas[\"total_viagens\"].sum())\n",
    "        diff_receita = abs(resultado_duckdb[\"receita_total\"].sum() - resultado_pandas[\"receita_total\"].sum())\n",
    "\n",
    "        print(\"\\n=== Validação ===\")\n",
    "        print(f\"Diferença total_viagens: {diff_viagens}\")\n",
    "        print(f\"Diferença receita_total: {diff_receita}\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Não foi possível comparar resultados:\", e)\n",
    "\n",
    "# ============================================================\n",
    "# 5️⃣ Comparação final\n",
    "# ============================================================\n",
    "comparacao = pd.DataFrame([\n",
    "    {\n",
    "        \"Consulta\": \"Padrões temporais (mês/semana)\",\n",
    "        \"Ferramenta\": \"DuckDB\",\n",
    "        \"Tempo Médio (s)\": round(tempo_medio_duckdb, 3),\n",
    "        \"Sucesso\": True, #Se chegar aqui vai ter dado certo mesmo \n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"Consulta\": \"Padrões temporais (mês/semana)\",\n",
    "        \"Ferramenta\": \"Pandas\",\n",
    "        \"Tempo Médio (s)\": round(tempo_medio_pandas, 3) if pandas_ok else None,\n",
    "        \"Sucesso\": pandas_ok,\n",
    "        \n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n=== Comparação Final ===\")\n",
    "print(comparacao)\n",
    "\n",
    "# (opcional) salvar resultados\n",
    "comparacao.to_csv(\"analysis_results/comparacao_duckdb_pandas.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
